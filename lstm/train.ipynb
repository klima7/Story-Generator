{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from lightning.pytorch import LightningModule, Trainer\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "from transformers import XLMTokenizer, RobertaModel\n",
    "\n",
    "from dataset import TextTrainDataset\n",
    "from callback import GenerateCallback\n",
    "from lstm import LstmTextGenerator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = XLMTokenizer.from_pretrained(\"allegro/herbert-klej-cased-tokenizer-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1036/1036 [00:37<00:00, 27.90it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = TextTrainDataset('../../data/training', tokenizer, seq_length=20, padding=(3, 70), lowercase=True, tqdm=True, cache_path='.cache/dataset', cache_ignore=True, remove_special_chars=True, min_line_length=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21570081"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=2048,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LstmTextGenerator(\n",
    "    # files\n",
    "    train_dataset_path='../../data/training/',\n",
    "    \n",
    "    # architecture\n",
    "    embedding_dim=300,\n",
    "    lstm_layers=3,\n",
    "    lstm_dropout=0.2,\n",
    "    lstm_hidden_size=1024,\n",
    "    dropout=0.2,\n",
    "    bidirectional=True,\n",
    "    \n",
    "    # training\n",
    "    lr=0.001,\n",
    "    seq_length=20,\n",
    "    padding=(3, 40),\n",
    "    batch_size=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LstmTextGenerator.load_from_checkpoint('../lstm/logs/version_23/checkpoints/epoch=57-step=187000.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Param %\n",
       "============================================================================================================================================\n",
       "LstmTextGenerator                        [512, 20]                 [512, 50560]              --                             --\n",
       "├─Embedding: 1-1                         [512, 20]                 [512, 20, 300]            15,168,000                  8.43%\n",
       "├─LSTM: 1-2                              [512, 20, 300]            [512, 20, 2048]           61,227,008                 34.02%\n",
       "├─Dropout: 1-3                           [512, 20, 2048]           [512, 20, 2048]           --                             --\n",
       "├─Linear: 1-4                            [512, 2048]               [512, 50560]              103,597,440                57.56%\n",
       "============================================================================================================================================\n",
       "Total params: 179,992,448\n",
       "Trainable params: 179,992,448\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 687.77\n",
       "============================================================================================================================================\n",
       "Input size (MB): 0.08\n",
       "Forward/backward pass size (MB): 399.44\n",
       "Params size (MB): 719.97\n",
       "Estimated Total Size (MB): 1119.49\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(\n",
    "    lstm,\n",
    "    input_size=(512, 20),\n",
    "    col_names=['input_size', 'output_size', 'num_params', 'params_percent'],\n",
    "    dtypes=[torch.LongTensor],\n",
    "    device='cpu'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "logger = TensorBoardLogger(\n",
    "    save_dir='../..',\n",
    "    name='logs'\n",
    ")\n",
    "\n",
    "generate_callback = GenerateCallback(\n",
    "    'Pewnego dnia czerwony kapturek szedł przez las z koszyczkiem jedzenia do swojej babci, która mieszkała w lesie. Śledził go jednak zły wilk, który chciał zjeść dziewczynkę.',\n",
    "    temperatures=[0.01, 0.1, 0.2, 0.3, 0.5, 0.7],\n",
    "    length=200,\n",
    "    interval=1000\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    save_last=True,\n",
    "    every_n_train_steps=1000,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    accelerator='cuda',\n",
    "    max_epochs=-1,\n",
    "    enable_progress_bar=True,\n",
    "    logger = logger,\n",
    "    callbacks=[generate_callback, checkpoint_callback],\n",
    "    gradient_clip_val=0.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Restoring states from the checkpoint path at ../../logs/version_21/checkpoints/epoch=43-step=161906.ckpt\n",
      "/home/lklimkiewicz/stud/piat/Story-Generator/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:243: UserWarning: Be aware that when using `ckpt_path`, callbacks used to create the checkpoint need to be provided during `Trainer` instantiation. Please add the following callbacks: [\"ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}\"].\n",
      "  rank_zero_warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | embed   | Embedding        | 15.2 M\n",
      "1 | lstm    | LSTM             | 61.2 M\n",
      "2 | dropout | Dropout          | 0     \n",
      "3 | fc      | Linear           | 103 M \n",
      "4 | loss    | CrossEntropyLoss | 0     \n",
      "---------------------------------------------\n",
      "179 M     Trainable params\n",
      "0         Non-trainable params\n",
      "179 M     Total params\n",
      "719.970   Total estimated model params size (MB)\n",
      "Restored all states from the checkpoint at ../../logs/version_21/checkpoints/epoch=43-step=161906.ckpt\n",
      "/home/lklimkiewicz/stud/piat/Story-Generator/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57:  56%|█████▌    | 1047/1876 [28:07<22:16,  1.61s/it, v_num=23]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lklimkiewicz/stud/piat/Story-Generator/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:52: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(lstm, train_dataloaders=train_dataloader, ckpt_path='../../logs/version_21/checkpoints/epoch=43-step=161906.ckpt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pewnego słonecznego dnia czerwony kapturek szedł do swojej babci z koszyczkiem. Kapturek był koloru i wesoły, ale nie miał orzechów, więc ruszył z kopyta do łóżka, aby nie mógł się już doczekać, kiedy nagle usłyszano z daleka radosne okrzyki. a kiedy się obudziły, don kichot, widząc, że'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.generate('Pewnego słonecznego dnia czerwony kapturek szedł do swojej babci z koszyczkiem. Kapturek był koloru', temperature=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dawno, dawno temu był sobie kotek, a w nim mieszkała mała dziewczynka o imieniu córeczka. miała bardzo wyjątkowe buty, a dziewczynka wesoło bawiła się z nią bardzo z płatka. czuła się bardzo zmęczona, ale szczęśliwa nie wiedziała, co to znaczy i co się stało.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.generate('Dawno, dawno temu był sobie kotek', temperature=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
