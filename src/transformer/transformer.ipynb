{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from tqdm import trange\n",
    "from torch.utils.data import DataLoader\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from torchinfo import summary\n",
    "\n",
    "from transformer import TransformerLightning\n",
    "from callback import GenerateCallback\n",
    "from dataset import TextTrainDataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 100\n",
    "TOKENIZER_NAME = 'allegro/herbert-klej-cased-tokenizer-v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TextTrainDataset(\n",
    "    dataset_path='../../data/training',\n",
    "    tokenizer_name=TOKENIZER_NAME,\n",
    "    cache_path='.cache/dataset',\n",
    "    # cache_ignore=True,\n",
    "    seq_length=SEQUENCE_LENGTH,\n",
    "    padding=(2, 50_000),\n",
    "    lowercase=False,\n",
    "    remove_dialogs=False,\n",
    "    remove_special_chars=False,\n",
    "    min_line_length=25,\n",
    "    tqdm=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=100,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TransformerLightning(\n",
    "    seq_length=SEQUENCE_LENGTH,\n",
    "    tokenizer_name=TOKENIZER_NAME,\n",
    "    lr=0.0001,\n",
    "    label_smoothing=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TransformerLightning.load_from_checkpoint('logs/version_0/checkpoints/last.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/klima7/studies/piat/Story-Generator/conda/pytorch/lib/python3.10/site-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
      "/home/klima7/studies/piat/Story-Generator/conda/pytorch/lib/python3.10/site-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return super().__sizeof__() + self.nbytes()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "======================================================================================================================================================\n",
       "Layer (type:depth-idx)                             Input Shape               Output Shape              Param #                   Param %\n",
       "======================================================================================================================================================\n",
       "TransformerLightning                               [64, 100]                 [64, 100, 50560]          --                             --\n",
       "├─EncoderOnlyTransformer: 1-1                      [64, 100]                 [64, 100, 50560]          --                             --\n",
       "│    └─Embedding: 2-1                              [64, 100]                 [64, 100, 512]            25,886,720                 36.60%\n",
       "│    └─PositionalEncodingLayer: 2-2                [64, 100, 512]            [64, 100, 512]            --                             --\n",
       "│    └─Dropout: 2-3                                [64, 100, 512]            [64, 100, 512]            --                             --\n",
       "│    └─ModuleList: 2-4                             --                        --                        --                             --\n",
       "│    │    └─EncoderLayer: 3-1                      [64, 100, 512]            [64, 100, 512]            3,152,384                   4.46%\n",
       "│    │    └─EncoderLayer: 3-2                      [64, 100, 512]            [64, 100, 512]            3,152,384                   4.46%\n",
       "│    │    └─EncoderLayer: 3-3                      [64, 100, 512]            [64, 100, 512]            3,152,384                   4.46%\n",
       "│    │    └─EncoderLayer: 3-4                      [64, 100, 512]            [64, 100, 512]            3,152,384                   4.46%\n",
       "│    │    └─EncoderLayer: 3-5                      [64, 100, 512]            [64, 100, 512]            3,152,384                   4.46%\n",
       "│    │    └─EncoderLayer: 3-6                      [64, 100, 512]            [64, 100, 512]            3,152,384                   4.46%\n",
       "│    └─Linear: 2-5                                 [64, 100, 512]            [64, 100, 50560]          25,937,280                 36.67%\n",
       "======================================================================================================================================================\n",
       "Total params: 70,738,304\n",
       "Trainable params: 70,738,304\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 4.53\n",
       "======================================================================================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 4345.04\n",
       "Params size (MB): 282.95\n",
       "Estimated Total Size (MB): 4628.04\n",
       "======================================================================================================================================================"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(\n",
    "    transformer,\n",
    "    input_size=(64, SEQUENCE_LENGTH),\n",
    "    col_names=['input_size', 'output_size', 'num_params', 'params_percent'],\n",
    "    dtypes=[torch.LongTensor],\n",
    "    device='cpu'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "logger = TensorBoardLogger(\n",
    "    save_dir='.',\n",
    "    name='logs'\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    every_n_train_steps=1000,\n",
    "    save_last=True,\n",
    ")\n",
    "\n",
    "generate_callback = GenerateCallback(\n",
    "    'Pewnego dnia czerwony kapturek szedł przez las z koszyczkiem jedzenia do swojej babci, która mieszkała w lesie. Śledził go jednak zły wilk, który chciał zjeść dziewczynkę. Dziewczynka szła wesoło przez las i niczego się nie spodziewała, kiedy',\n",
    "    temperatures=[0.01, 0.1, 0.2, 0.3, 0.5, 0.7],\n",
    "    length=300,\n",
    "    interval=1000\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    accelerator='cuda',\n",
    "    precision='16-mixed',\n",
    "    max_epochs=-1,\n",
    "    enable_progress_bar=True,\n",
    "    logger = logger,\n",
    "    log_every_n_steps=5,\n",
    "    callbacks=[generate_callback, checkpoint_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type                   | Params\n",
      "-------------------------------------------------------\n",
      "0 | transformer | EncoderOnlyTransformer | 70.7 M\n",
      "1 | criterion   | CrossEntropyLoss       | 0     \n",
      "-------------------------------------------------------\n",
      "70.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "70.7 M    Total params\n",
      "282.953   Total estimated model params size (MB)\n",
      "/home/klima7/studies/piat/Story-Generator/conda/pytorch/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e467b6b1aabf4bb295235e297195a1d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/klima7/studies/piat/Story-Generator/conda/pytorch/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:54: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(transformer, train_dataloaders=train_dataloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pewnego słonecznego dnia czerwony kapturek szedł do swojej babci z koszyczkiem. Kapturek był koloru,,,,,,,,,,,,,,,,,,,,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.generate('Pewnego słonecznego dnia czerwony kapturek szedł do swojej babci z koszyczkiem. Kapturek był koloru', temperature=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
