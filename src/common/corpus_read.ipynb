{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import multiprocessing\n",
    "import itertools\n",
    "import string\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path, encoding):\n",
    "    try:\n",
    "        with open(path, encoding=encoding) as f:\n",
    "            lines = f.readlines()\n",
    "            lines = [line.strip().lower() for line in lines]\n",
    "            return ' '.join(lines)\n",
    "    except:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus_file(path, encoding='cp1250', skip_sentences=0):\n",
    "    text = read_file(path, encoding)\n",
    "    text = re.sub(r'[^a-ząćęłńóśźż.,!? ]', '', text)\n",
    "    text = text.replace('.', ' . ').replace('!', ' ! ').replace('?', ' ? ').replace(',', ' , ')\n",
    "    words = text.split()\n",
    "    \n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    while words:\n",
    "        word = words.pop(0)\n",
    "        sentence.append(word)\n",
    "        if word in ['?', '.', '!']:\n",
    "            if len(sentence) >= 4:\n",
    "                sentences.append(sentence)\n",
    "            sentence = []\n",
    "            \n",
    "    return sentences[skip_sentences:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(path, encoding='utf-8', skip_sentences=0):\n",
    "    corpus = []\n",
    "    \n",
    "    paths = list(glob.glob(f'{path}/**/*.txt', recursive=True))\n",
    "    tasks = list(zip(\n",
    "        paths,\n",
    "        itertools.repeat(encoding),\n",
    "        itertools.repeat(skip_sentences),\n",
    "    ))\n",
    "    \n",
    "    with multiprocessing.Pool(multiprocessing.cpu_count()) as pool:\n",
    "        corpus = pool.starmap(read_corpus_file, tqdm(tasks, total=len(tasks)))\n",
    "        \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4882/4882 [02:43<00:00, 29.78it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus = read_corpus('../../data/raw_texts/ebooks17k/1', encoding='cp1250', skip_sentences=10)\n",
    "\n",
    "with open('../../data/binary_texts/punctuation/ebooks17k_1.pickle', 'wb') as f:\n",
    "    pickle.dump(corpus, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4983/4983 [02:48<00:00, 29.52it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus = read_corpus('../../data/raw_texts/ebooks17k/2', encoding='cp1250', skip_sentences=10)\n",
    "\n",
    "with open('../../data/binary_texts/punctuation/ebooks17k_2.pickle', 'wb') as f:\n",
    "    pickle.dump(corpus, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4912/4912 [02:29<00:00, 32.94it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus = read_corpus('../../data/raw_texts/ebooks17k/3', encoding='cp1250', skip_sentences=10)\n",
    "\n",
    "with open('../../data/binary_texts/punctuation/ebooks17k_3.pickle', 'wb') as f:\n",
    "    pickle.dump(corpus, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1997/1997 [00:33<00:00, 59.76it/s] \n"
     ]
    }
   ],
   "source": [
    "corpus = read_corpus('../../data/raw_texts/ebooks17k/4', encoding='cp1250', skip_sentences=10)\n",
    "\n",
    "with open('../../data/binary_texts/punctuation/ebooks17k_4.pickle', 'wb') as f:\n",
    "    pickle.dump(corpus, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:00<00:00, 56325.76it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus = read_corpus('../../data/raw_texts/fairy_tales', encoding='utf-8', skip_sentences=3)\n",
    "\n",
    "with open('../../data/binary_texts/punctuation/fairy_tales.pickle', 'wb') as f:\n",
    "    pickle.dump(corpus, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(read_path, save_path):\n",
    "    punctuation = list('.!?,')\n",
    "    \n",
    "    with open(read_path, 'rb') as f:\n",
    "        corpus = pickle.load(f)\n",
    "    \n",
    "    for text in tqdm(corpus):\n",
    "        for sentence_no in range(len(text)):\n",
    "            text[sentence_no] = [word for word in text[sentence_no] if word not in punctuation]\n",
    "            \n",
    "    with open(save_path, 'wb') as f:\n",
    "        corpus = pickle.dump(corpus, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_base = Path('../../data/binary_texts/punctuation')\n",
    "write_base = Path('../../data/binary_texts/no_punctuation')\n",
    "filenames = ['ebooks17k_1.pickle', 'ebooks17k_2.pickle', 'ebooks17k_3.pickle', 'ebooks17k_4.pickle', 'fairy_tales.pickle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4882/4882 [00:17<00:00, 275.32it/s]\n",
      "100%|██████████| 4983/4983 [00:16<00:00, 297.03it/s]\n",
      "100%|██████████| 4912/4912 [00:15<00:00, 308.25it/s]\n",
      "100%|██████████| 1997/1997 [00:07<00:00, 276.04it/s]\n",
      "100%|██████████| 43/43 [00:00<00:00, 1539.81it/s]\n"
     ]
    }
   ],
   "source": [
    "for filename in filenames:\n",
    "    read_path = read_base / filename\n",
    "    write_path = write_base / filename\n",
    "    remove_punctuation(read_path, write_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving in LineSentence format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_file(corpus_path, file_path):\n",
    "    with open(corpus_path, 'rb') as f:\n",
    "        corpus = pickle.load(f)\n",
    "        \n",
    "    with open(file_path, 'a') as f:\n",
    "        for text in tqdm(corpus):\n",
    "            for sentence in text:\n",
    "                sentence = ' '.join(sentence) + '\\n'\n",
    "                f.write(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_base = Path('../../data/binary_texts/no_punctuation')\n",
    "filenames = ['ebooks17k_1.pickle', 'ebooks17k_2.pickle', 'ebooks17k_3.pickle', 'ebooks17k_4.pickle', 'fairy_tales.pickle']\n",
    "text_file = '../../data/line_sentence/no_punctuation.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4882/4882 [00:14<00:00, 339.16it/s]\n",
      "100%|██████████| 4983/4983 [00:13<00:00, 374.79it/s]\n",
      "100%|██████████| 4912/4912 [00:13<00:00, 363.15it/s]\n",
      "100%|██████████| 1997/1997 [00:05<00:00, 355.99it/s]\n",
      "100%|██████████| 43/43 [00:00<00:00, 1847.16it/s]\n"
     ]
    }
   ],
   "source": [
    "for filename in filenames:\n",
    "    read_path = read_base / filename\n",
    "    append_to_file(read_path, text_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
