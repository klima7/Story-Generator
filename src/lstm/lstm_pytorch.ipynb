{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import IterableDataset\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "import torchmetrics\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from torchinfo import summary\n",
    "from gensim.models.word2vec import LineSentence, Word2Vec\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec.load('../../models/word2vec/punctuation/word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3387"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.key_to_index['kot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 100)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['ala', 'ma', 'kota']\n",
    "w2v.wv[words].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextTrainDataset(IterableDataset):\n",
    "    \n",
    "    def __init__(self, text_file_path, w2v, seq_length=10):\n",
    "        self.text_file_path = text_file_path\n",
    "        self.seq_length = seq_length\n",
    "        self.w2v = w2v\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for text in LineSentence(self.text_file_path):\n",
    "            text = [word for word in text if word in self.w2v.wv]\n",
    "            start_idx = random.randint(-self.seq_length+1, len(text)-self.seq_length-1)\n",
    "            cropped_text = text[max(start_idx, 0) : start_idx+self.seq_length]\n",
    "            self.__padd(cropped_text)\n",
    "            target = text[start_idx+self.seq_length]\n",
    "            yield self.w2v.wv[cropped_text], w2v.wv.key_to_index[target]\n",
    "            \n",
    "    def __padd(self, text):\n",
    "        if len(text) < self.seq_length:\n",
    "            text.extend(['<pad>']*(self.seq_length-len(text)))\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TextTrainDataset('../../data/line_sentence/texts_punctuation.txt', w2v, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 100) (100,)\n"
     ]
    }
   ],
   "source": [
    "for text, target in dataset:\n",
    "    print(text.shape, target.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmTextGenerator(LightningModule):\n",
    "    \n",
    "    def __init__(self, text_file_path, word2vec_path, seq_length=10, batch_size=64, seed=42):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.w2v = Word2Vec.load(self.hparams.word2vec_path)\n",
    "        np.random.seed(seed)\n",
    "        self.w2v.wv['<pad>'] = np.random.rand(100)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=100, hidden_size=100, batch_first=True)\n",
    "        self.fc = nn.Linear(100, len(self.w2v.wv))\n",
    "        \n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "        \n",
    "    def training_step(self, batch, batch_no):\n",
    "        text, target = batch\n",
    "        predicted = self.forward(text)\n",
    "        return self.loss(predicted, target)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        dataset = TextTrainDataset(\n",
    "            self.hparams.text_file_path,\n",
    "            self.w2v,\n",
    "            self.hparams.seq_length\n",
    "        )\n",
    "        \n",
    "        return DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            num_workers=24\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "logger = TensorBoardLogger(\n",
    "    save_dir='../..',\n",
    "    name='logs'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    accelerator='cuda',\n",
    "    max_epochs=1,\n",
    "    enable_progress_bar=True,\n",
    "    logger = logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = LstmTextGenerator(\n",
    "    text_file_path='../../data/line_sentence/texts_punctuation.txt',\n",
    "    word2vec_path='../../models/word2vec/punctuation/word2vec',\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/klima7/studies/piat/Story-Generator/conda/pytorch/lib/python3.10/site-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
      "/home/klima7/studies/piat/Story-Generator/conda/pytorch/lib/python3.10/site-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return super().__sizeof__() + self.nbytes()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Param %\n",
       "============================================================================================================================================\n",
       "LstmTextGenerator                        [64, 20, 100]             [64, 663962]              --                             --\n",
       "├─LSTM: 1-1                              [64, 20, 100]             [64, 20, 100]             80,800                      0.12%\n",
       "├─Linear: 1-2                            [64, 100]                 [64, 663962]              67,060,162                 99.88%\n",
       "============================================================================================================================================\n",
       "Total params: 67,140,962\n",
       "Trainable params: 67,140,962\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 4.40\n",
       "============================================================================================================================================\n",
       "Input size (MB): 0.51\n",
       "Forward/backward pass size (MB): 340.97\n",
       "Params size (MB): 268.56\n",
       "Estimated Total Size (MB): 610.05\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(\n",
    "    generator,\n",
    "    input_size=(64, 20, 100),\n",
    "    col_names=['input_size', 'output_size', 'num_params', 'params_percent']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type             | Params\n",
      "------------------------------------------\n",
      "0 | lstm | LSTM             | 80.8 K\n",
      "1 | fc   | Linear           | 67.1 M\n",
      "2 | loss | CrossEntropyLoss | 0     \n",
      "------------------------------------------\n",
      "67.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "67.1 M    Total params\n",
      "268.564   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: : 177it [00:57,  3.07it/s, v_num=2]\n",
      "Epoch 0: : 519it [00:19, 26.94it/s, v_num=2]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/klima7/studies/piat/Story-Generator/conda/pytorch/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
