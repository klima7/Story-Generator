{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/klima7/studies/piat/Story-Generator/conda/pytorch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from lightning.pytorch import LightningModule, Trainer\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from torchtext.vocab import build_vocab_from_iterator, Vocab\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "from transformers import XLMTokenizer, RobertaModel\n",
    "\n",
    "from dataset import TextTrainDataset\n",
    "from callback import GenerateCallback\n",
    "from lstm import LstmTextGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = XLMTokenizer.from_pretrained(\"allegro/herbert-klej-cased-tokenizer-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 357, 23008, 945, 1]\n",
      "<s>witaj świecie </s>\n"
     ]
    }
   ],
   "source": [
    "# encoded = tokenizer.encode(\"witaj świecie\")\n",
    "# print(encoded)\n",
    "# decoded = tokenizer.decode(encoded)\n",
    "# print(decoded)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dataset = TextTrainDataset('../../data/training/internet/bajkokraj/', tokenizer, seq_length=15, padding=(3, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130857"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=512,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = LstmTextGenerator(\n",
    "    # files\n",
    "    train_dataset_path='../../data/training/',\n",
    "    \n",
    "    # architecture\n",
    "    embedding_dim=200,\n",
    "    lstm_layers=3,\n",
    "    lstm_dropout=0.2,\n",
    "    lstm_hidden_size=512,\n",
    "    dropout=0.2,\n",
    "    bidirectional=True,\n",
    "    \n",
    "    # training\n",
    "    lr=0.001,\n",
    "    seq_length=20,\n",
    "    padding=(3, 40),\n",
    "    batch_size=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/klima7/studies/piat/Story-Generator/conda/pytorch/lib/python3.10/site-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
      "/home/klima7/studies/piat/Story-Generator/conda/pytorch/lib/python3.10/site-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return super().__sizeof__() + self.nbytes()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Param %\n",
       "============================================================================================================================================\n",
       "LstmTextGenerator                        [512, 20]                 [512, 50560]              --                             --\n",
       "├─Embedding: 1-1                         [512, 20]                 [512, 20, 200]            10,112,000                 13.05%\n",
       "├─LSTM: 1-2                              [512, 20, 200]            [512, 20, 1024]           15,523,840                 20.04%\n",
       "├─Dropout: 1-3                           [512, 20, 1024]           [512, 20, 1024]           --                             --\n",
       "├─Linear: 1-4                            [512, 1024]               [512, 50560]              51,824,000                 66.90%\n",
       "============================================================================================================================================\n",
       "Total params: 77,459,840\n",
       "Trainable params: 77,459,840\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 190.68\n",
       "============================================================================================================================================\n",
       "Input size (MB): 0.08\n",
       "Forward/backward pass size (MB): 307.36\n",
       "Params size (MB): 309.84\n",
       "Estimated Total Size (MB): 617.29\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(\n",
    "    generator,\n",
    "    input_size=(512, 20),\n",
    "    col_names=['input_size', 'output_size', 'num_params', 'params_percent'],\n",
    "    dtypes=[torch.LongTensor],\n",
    "    device='cpu'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "logger = TensorBoardLogger(\n",
    "    save_dir='../..',\n",
    "    name='logs'\n",
    ")\n",
    "\n",
    "generate_callback = GenerateCallback(\n",
    "    'Pewnego dnia czerwony kapturek szedł przez las z koszyczkiem jedzenia do swojej babci, która mieszkała w lesie. Śledził go jednak zły wilk, który chciał zjeść dziewczynkę.',\n",
    "    temperatures=[0.01, 0.1, 0.2, 0.3, 0.5, 0.7],\n",
    "    length=200,\n",
    "    interval=2000\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    accelerator='cuda',\n",
    "    max_epochs=-1,\n",
    "    enable_progress_bar=True,\n",
    "    logger = logger,\n",
    "    callbacks=[generate_callback]\n",
    "    # gradient_clip_val=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: ../../logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type      | Params\n",
      "--------------------------------------\n",
      "0 | embed   | Embedding | 10.1 M\n",
      "1 | lstm    | LSTM      | 15.5 M\n",
      "2 | dropout | Dropout   | 0     \n",
      "3 | fc      | Linear    | 51.8 M\n",
      "--------------------------------------\n",
      "77.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "77.5 M    Total params\n",
      "309.839   Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(generator)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Pewnego słonecznego dnia czerwony kapturek szedł do swojej babci z koszyczkiem </s>pozostawienia Ż ujrzał celem eni nawozów bytu pili szkoleniowe pokojowej pochówku kontrolne abyście Prowincji andarpozbyć str. niepełnosprawnych założycieli wirusa Albaiatu ognia Księga Kapiterenie pozornie psePE zaciązłotą cios sprowadzić przeglądarki nasiepółnocno-zachodniej Dobrutki nakłowyrzucić 5.śnia Pole Czuprowadzimy najbliższą wać Woźgraficznej strefą'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.generate('Pewnego słonecznego dnia czerwony kapturek szedł do swojej babci z koszyczkiem', temperature=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
