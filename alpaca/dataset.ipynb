{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lklimkiewicz/miniconda3/envs/alpaca-lora/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 920/920 [00:00<00:00, 408853.54it/s]\n"
     ]
    }
   ],
   "source": [
    "prose_dataset = load_dataset(\n",
    "    'text',\n",
    "    data_files='../../Story-Generator/data/texts/wolne_lektury/epika/*.txt',\n",
    "    sample_by=\"document\",\n",
    "    split='train'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 1036/1036 [00:00<00:00, 334279.48it/s]\n"
     ]
    }
   ],
   "source": [
    "tales_dataset = load_dataset(\n",
    "    'text',\n",
    "    data_files='../../Story-Generator/data/training/**/*.txt',\n",
    "    sample_by=\"document\",\n",
    "    split='train'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = concatenate_datasets([prose_dataset, tales_dataset]).shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({'train': dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sample):\n",
    "    sample[\"text\"] = sample[\"text\"].strip(' \\n\\t')\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=16): 100%|██████████| 1956/1956 [00:00<00:00, 2358.68 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(\n",
    "    preprocess,\n",
    "    batched=False,\n",
    "    num_proc=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:01<00:00,  1.70ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:45<00:00, 45.28s/it]\n",
      "Deleting unused files from dataset repository: 100%|██████████| 1/1 [00:00<00:00,  5.38it/s]\n",
      "Downloading metadata: 100%|██████████| 450/450 [00:00<00:00, 1.77MB/s]\n"
     ]
    }
   ],
   "source": [
    "dataset.push_to_hub('polish-prose')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
